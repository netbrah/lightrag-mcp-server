"""
Mock OpenAI API responses for integration testing.
Only mocks the API calls - all other LightRAG functionality is real.
"""

import json
from pathlib import Path
from typing import List, Dict, Any, Optional
import numpy as np
import hashlib


class MockOpenAIResponse:
    """Mock OpenAI API responses with pre-recorded or generated data."""
    
    def __init__(self, fixtures_path: Optional[Path] = None):
        self.fixtures_path = fixtures_path
        self.call_count = 0
        self.completion_count = 0
        self.embedding_count = 0
        
    async def mock_complete(
        self, 
        prompt: str, 
        system_prompt: Optional[str] = None,
        **kwargs
    ) -> str:
        """
        Mock LLM completion with realistic responses based on prompt content.
        """
        self.call_count += 1
        self.completion_count += 1
        
        prompt_lower = prompt.lower()
        
        # Entity extraction request
        if "extract" in prompt_lower and ("entit" in prompt_lower or "relationship" in prompt_lower):
            return self._generate_entity_extraction_response(prompt)
        
        # Summary request
        if "summar" in prompt_lower or "describe" in prompt_lower:
            return self._generate_summary_response(prompt)
        
        # Query/question answering
        if "?" in prompt or "what" in prompt_lower or "how" in prompt_lower or "where" in prompt_lower:
            return self._generate_query_response(prompt)
        
        # Default response
        return "This is a mock LLM response. The actual content would be generated by the real OpenAI API."
    
    def _generate_entity_extraction_response(self, prompt: str) -> str:
        """Generate entity extraction response from code."""
        # Extract entities from the prompt (simplified)
        entities = []
        relationships = []
        
        # Look for common code patterns - check the actual content
        prompt_lower = prompt.lower()
        
        # Extract entities based on content  
        if "reversestring" in prompt_lower or "reverse" in prompt_lower:
            entities.append({
                "entity_name": "reverseString",
                "entity_type": "function",
                "description": "Function that reverses a string using STL algorithms. Takes a string and returns it reversed.",
                "source_id": "utils.cpp"
            })
        
        if "touppercase" in prompt_lower or "uppercase" in prompt_lower or "toupper" in prompt_lower:
            entities.append({
                "entity_name": "toUpperCase",
                "entity_type": "function",
                "description": "Function that converts a string to uppercase using std::transform",
                "source_id": "utils.cpp"
            })
        
        if "tolowercase" in prompt_lower or "lowercase" in prompt_lower or "tolower" in prompt_lower:
            entities.append({
                "entity_name": "toLowerCase",
                "entity_type": "function",
                "description": "Function that converts a string to lowercase using std::transform",
                "source_id": "utils.cpp"
            })
        
        if "ispalindrome" in prompt_lower or "palindrome" in prompt_lower:
            entities.append({
                "entity_name": "isPalindrome",
                "entity_type": "function",
                "description": "Function that checks if a string is a palindrome by comparing with reversed version",
                "source_id": "utils.cpp"
            })
        
        if "main" in prompt_lower or "entry" in prompt_lower:
            entities.append({
                "entity_name": "main",
                "entity_type": "function",
                "description": "Main entry point for the StringProcessor application. Handles command line input and demonstrates string operations.",
                "source_id": "main.cpp"
            })
        
        if "stringprocessor" in prompt_lower or "application" in prompt_lower:
            entities.append({
                "entity_name": "StringProcessor",
                "entity_type": "application",
                "description": "Main application for string manipulation operations including reverse, case conversion, and palindrome checking",
                "source_id": "main.cpp"
            })
        
        # Add generic utils entity
        if "util" in prompt_lower or not entities:
            entities.append({
                "entity_name": "StringUtils",
                "entity_type": "module",
                "description": "Utility module containing string manipulation functions",
                "source_id": "utils.cpp"
            })
        
        # Generate relationships
        if len(entities) > 1:
            # Main calls utils functions
            if any(e["entity_name"] == "main" for e in entities):
                for entity in entities:
                    if entity["entity_type"] == "function" and entity["entity_name"] != "main":
                        relationships.append({
                            "src_id": "main",
                            "tgt_id": entity["entity_name"],
                            "description": f"main function calls {entity['entity_name']} for string manipulation",
                            "keywords": "function_call,dependency,usage",
                            "weight": 0.9
                        })
        
        # Always create at least one entity to ensure data is stored
        if not entities:
            entities.append({
                "entity_name": "code_content",
                "entity_type": "content",
                "description": "Source code content with string manipulation functionality",
                "source_id": "source"
            })
        
        result = {
            "entities": entities,
            "relationships": relationships
        }
        
        return json.dumps(result, indent=2)
    
    def _generate_summary_response(self, prompt: str) -> str:
        """Generate summary response."""
        prompt_lower = prompt.lower()
        
        if "stringprocessor" in prompt_lower or "application" in prompt_lower:
            return """The StringProcessor is a C++ application that provides string manipulation utilities. It includes functions for reversing strings, converting case (uppercase/lowercase), and checking palindromes. The architecture consists of a main entry point that handles command-line input and a utilities module containing the core string manipulation functions."""
        
        if "reverse" in prompt_lower:
            return """The reverseString function takes a string input and returns it reversed using STL's std::reverse algorithm. It creates a copy of the input string and reverses it in-place."""
        
        if "uppercase" in prompt_lower or "lowercase" in prompt_lower:
            return """The case conversion functions (toUpperCase and toLowerCase) use std::transform with std::toupper/tolower to convert all characters in a string to the desired case."""
        
        if "palindrome" in prompt_lower:
            return """The isPalindrome function checks if a string reads the same forwards and backwards by comparing it with its reversed version."""
        
        return "This is a C++ codebase implementing string manipulation utilities including reversal, case conversion, and palindrome checking."
    
    def _generate_query_response(self, prompt: str) -> str:
        """Generate query response."""
        prompt_lower = prompt.lower()
        
        if "function" in prompt_lower and ("available" in prompt_lower or "manipulation" in prompt_lower):
            return """The codebase provides the following string manipulation functions:

1. **reverseString(str)**: Reverses the input string using STL algorithms
2. **toUpperCase(str)**: Converts all characters to uppercase
3. **toLowerCase(str)**: Converts all characters to lowercase
4. **isPalindrome(str)**: Checks if a string is a palindrome

These functions are defined in utils.cpp and declared in utils.h."""
        
        if "architecture" in prompt_lower or "overall" in prompt_lower:
            return """The application follows a modular architecture:

- **main.cpp**: Entry point and CLI interface, handles argument parsing and orchestrates function calls
- **utils.cpp/h**: Core string manipulation library with reusable functions
- **config.h**: Configuration constants including APP_NAME, APP_VERSION, and MAX_STRING_LENGTH

The main function receives user input, calls the appropriate utility functions, and displays the results."""
        
        if "reverse" in prompt_lower and "work" in prompt_lower:
            return """The reverseString function works by:
1. Creating a copy of the input string
2. Using std::reverse from the algorithm library to reverse the characters in-place
3. Returning the reversed string

Example: reverseString("hello") returns "olleh"

The implementation leverages STL algorithms for efficiency and readability."""
        
        if "error" in prompt_lower or "handling" in prompt_lower:
            return """The application includes basic error handling:
- Checks if sufficient command-line arguments are provided
- Validates string length against MAX_STRING_LENGTH constant
- Returns appropriate exit codes (0 for success, 1 for error)"""
        
        return "The StringProcessor application provides various string manipulation utilities implemented in C++ using STL algorithms."
    
    async def mock_embed(self, texts: List[str]) -> np.ndarray:
        """
        Mock embedding generation with deterministic vectors.
        Uses hash-based embeddings for reproducibility.
        """
        self.call_count += 1
        self.embedding_count += 1
        
        embeddings = []
        embedding_dim = 1536  # OpenAI text-embedding-3-large dimension
        
        for text in texts:
            # Generate deterministic embedding based on text hash
            text_hash = hashlib.sha256(text.encode()).hexdigest()
            seed = int(text_hash[:8], 16) % (2**32)
            np.random.seed(seed)
            
            # Generate random vector
            embedding = np.random.randn(embedding_dim)
            
            # Normalize to unit length (cosine similarity)
            norm = np.linalg.norm(embedding)
            if norm > 0:
                embedding = embedding / norm
            
            embeddings.append(embedding)
        
        return np.array(embeddings)


def patch_openai_for_lightrag():
    """
    Create mock functions compatible with LightRAG's expected signatures.
    Returns mock_complete and mock_embed functions.
    """
    mock_client = MockOpenAIResponse()
    
    async def openai_complete_if_cache(
        prompt,
        system_prompt=None,
        history_messages=[],
        **kwargs
    ) -> str:
        """Mock compatible with LightRAG's openai_complete_if_cache."""
        return await mock_client.mock_complete(
            prompt=prompt,
            system_prompt=system_prompt,
            **kwargs
        )
    
    async def openai_embed(texts: List[str], **kwargs) -> np.ndarray:
        """Mock compatible with LightRAG's openai_embed."""
        if isinstance(texts, str):
            texts = [texts]
        return await mock_client.mock_embed(texts)
    
    # Add embedding_dim attribute for Milvus compatibility
    openai_embed.embedding_dim = 1536
    
    return mock_client, openai_complete_if_cache, openai_embed
